{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic_image_segmentation_unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "hr2F9b_dmEs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "input_dir = \"/gdrive/MyDrive/Colab Notebooks/original images\"\n",
        "target_dir = \"/gdrive/MyDrive/Colab Notebooks/annotated images\"\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [os.path.join(input_dir, fname)\n",
        "     for fname in os.listdir(input_dir)\n",
        "     if fname.endswith(\".jpg\")])\n",
        "target_paths = sorted(\n",
        "    [os.path.join(target_dir, fname)\n",
        "     for fname in os.listdir(target_dir)\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ],
      "metadata": {
        "id": "5ett52fDmKC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "img_size = (256, 256)\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_paths)\n",
        "\n",
        "def path_to_input_image(path):\n",
        "    return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "def path_to_target(path):\n",
        "    img = img_to_array(\n",
        "        load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
        "    img = img.astype(\"uint8\") - 1\n",
        "    return img\n",
        "\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "for i in range(num_imgs):\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "    targets[i] = path_to_target(target_paths[i])\n",
        "\n",
        "targets = targets*(1./255)\n",
        "\n",
        "num_val_samples = 30\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ],
      "metadata": {
        "id": "s9MWxitymK5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_targets))\n",
        "print(len(train_input_imgs))\n",
        "original = keras.preprocessing.image.array_to_img(train_input_imgs[1])\n",
        "display(original)\n",
        "original = keras.preprocessing.image.array_to_img(train_targets[1])\n",
        "display(original)"
      ],
      "metadata": {
        "id": "2wkcQiSb7-Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution_operation(entered_input, filters=64):\n",
        "    # Taking first input and implementing the first conv block\n",
        "    conv1 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(entered_input)\n",
        "    batch_norm1 = BatchNormalization()(conv1)\n",
        "    act1 = ReLU()(batch_norm1)\n",
        "    \n",
        "    # Taking first input and implementing the second conv block\n",
        "    conv2 = Conv2D(filters, kernel_size = (3,3), padding = \"same\")(act1)\n",
        "    batch_norm2 = BatchNormalization()(conv2)\n",
        "    act2 = ReLU()(batch_norm2)\n",
        "    return act2\n",
        "\n",
        "def encoder(entered_input, filters=64):\n",
        "    # Collect the start and end of each sub-block for normal pass and skip connections\n",
        "    enc1 = convolution_operation(entered_input, filters)\n",
        "    MaxPool1 = MaxPooling2D(strides = (2,2))(enc1)\n",
        "    return enc1, MaxPool1\n",
        "\n",
        "def decoder(entered_input, skip, filters=64):\n",
        "    # Upsampling and concatenating the essential features\n",
        "    Upsample = Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(entered_input)\n",
        "    Connect_Skip = Concatenate()([Upsample, skip])\n",
        "    out = convolution_operation(Connect_Skip, filters)\n",
        "    return out"
      ],
      "metadata": {
        "id": "qX5XLLIomPpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "def U_Net(Image_Size):\n",
        "    # Take the image size and shape\n",
        "    input = Input(shape=img_size + (3,))\n",
        "    input1 = layers.Rescaling(1./255)(input)\n",
        "\n",
        "    # Construct the encoder blocks\n",
        "    skip1, encoder_1 = encoder(input1, 64)\n",
        "    skip2, encoder_2 = encoder(encoder_1, 64*2)\n",
        "    skip3, encoder_3 = encoder(encoder_2, 64*4)\n",
        "    skip4, encoder_4 = encoder(encoder_3, 64*8)\n",
        "    \n",
        "    # Preparing the next block\n",
        "    conv_block = convolution_operation(encoder_4, 64*16)\n",
        "    \n",
        "    # Construct the decoder blocks\n",
        "    decoder_1 = decoder(conv_block, skip4, 64*8)\n",
        "    decoder_2 = decoder(decoder_1, skip3, 64*4)\n",
        "    decoder_3 = decoder(decoder_2, skip2, 64*2)\n",
        "    decoder_4 = decoder(decoder_3, skip1, 64)\n",
        "    \n",
        "    out = Conv2D(num_classes, 1, activation=\"sigmoid\", padding=\"same\")(decoder_4)\n",
        "    model = Model(input1, out)\n",
        "    return model\n",
        "\n",
        "input_shape = img_size\n",
        "model = U_Net(input_shape)"
      ],
      "metadata": {
        "id": "n5RSD86DmR9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"/gdrive/MyDrive/Colab Notebooks/unet.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets,\n",
        "                    epochs=50,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=(val_input_imgs, val_targets))"
      ],
      "metadata": {
        "id": "Ir2FmezlmVCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "-bQ4Xf8E8pfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"/gdrive/MyDrive/Colab Notebooks/unet.keras\")"
      ],
      "metadata": {
        "id": "RNSTRgkj3DwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=24\n",
        "test_image = train_input_imgs[i]\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(keras.preprocessing.image.array_to_img(test_image))"
      ],
      "metadata": {
        "id": "CdS1WjRS_zDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = model.predict(np.expand_dims(test_image, 0))[0]\n",
        "def display_mask(pred):\n",
        "  mask = np.argmax(pred, axis=-1)\n",
        "  mask *= 127\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(mask)\n",
        "display_mask(mask)"
      ],
      "metadata": {
        "id": "ATkJPlPWAzRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = train_targets[i]\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(keras.preprocessing.image.array_to_img(test_image))"
      ],
      "metadata": {
        "id": "YWI8cuGZBVQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
